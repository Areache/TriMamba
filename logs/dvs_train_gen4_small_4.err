Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id nu0t4ndp.
wandb: Tracking run with wandb version 0.16.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: logging graph, to disable use `wandb.watch(log_graph=False)`
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

creating rnd access train datasets: 0it [00:00, ?it/s]creating rnd access train datasets: 2it [00:00,  7.44it/s]creating rnd access train datasets: 16it [00:00, 53.40it/s]creating rnd access train datasets: 30it [00:00, 81.27it/s]creating rnd access train datasets: 45it [00:00, 102.08it/s]creating rnd access train datasets: 60it [00:00, 115.48it/s]creating rnd access train datasets: 74it [00:00, 121.78it/s]creating rnd access train datasets: 90it [00:00, 130.72it/s]creating rnd access train datasets: 107it [00:00, 141.01it/s]creating rnd access train datasets: 123it [00:01, 146.17it/s]creating rnd access train datasets: 139it [00:01, 144.15it/s]creating rnd access train datasets: 154it [00:01, 136.90it/s]creating rnd access train datasets: 170it [00:01, 143.07it/s]creating rnd access train datasets: 188it [00:01, 151.79it/s]creating rnd access train datasets: 205it [00:01, 156.01it/s]creating rnd access train datasets: 222it [00:01, 159.50it/s]creating rnd access train datasets: 239it [00:01,creating rnd access train datasets: 0it [00:00, ?it/s]creating rnd access train datasets: 2it [00:00,  7.43it/s]creating rnd access train datasets: 17it [00:00, 55.37it/s]creating rnd access train datasets: 31it [00:00, 82.39it/s]creating rnd access train datasets: 46it [00:00, 102.38it/s]creating rnd access train datasets: 61it [00:00, 116.15it/s]creating rnd access train datasets: 75it [00:00, 121.75it/s]creating rnd access train datasets: 91it [00:00, 130.64it/s]creating rnd access train datasets: 108it [00:00, 141.48it/s]creating rnd access train datasets: 123it [00:01, 109.94it/s]creating rnd access train datasets: 151it [00:01, 149.49it/s]creating rnd access train datasets: 168it [00:01, 151.28it/s]creating rnd access train datasets: 186it [00:01, 156.65it/s]creating rnd access train datasets: 203it [00:01, 159.13it/s]creating rnd access train datasets: 220it [00:01, 161.26it/s]creating rnd access train datasets: 237it [00:01, 160.56it/s]creating rnd access train datasets: 254it [00:01,creating rnd access train datasets: 0it [00:00, ?it/s]creating rnd access train datasets: 2it [00:00,  7.43it/s]creating rnd access train datasets: 16it [00:00, 53.37it/s]creating rnd access train datasets: 30it [00:00, 81.18it/s]creating rnd access train datasets: 45it [00:00, 102.00it/s]creating rnd access train datasets: 60it [00:00, 115.51it/s]creating rnd access train datasets: 74it [00:00, 121.80it/s]creating rnd access train datasets: 90it [00:00, 130.63it/s]creating rnd access train datasets: 107it [00:00, 141.15it/s]creating rnd access train datasets: 122it [00:01, 108.77it/s]creating rnd access train datasets: 150it [00:01, 149.96it/s]creating rnd access train datasets: 168it [00:01, 151.65it/s]creating rnd access train datasets: 186it [00:01, 156.87it/s]creating rnd access train datasets: 203it [00:01, 159.17it/s]creating rnd access train datasets: 220it [00:01, 161.37it/s]creating rnd access train datasets: 237it [00:01, 160.76it/s]creating rnd access train datasets: 254it [00:01,creating rnd access train datasets: 0it [00:00, ?it/s]creating rnd access train datasets: 2it [00:00,  7.43it/s]creating rnd access train datasets: 16it [00:00, 53.33it/s]creating rnd access train datasets: 30it [00:00, 81.26it/s]creating rnd access train datasets: 45it [00:00, 102.07it/s]creating rnd access train datasets: 60it [00:00, 115.39it/s]creating rnd access train datasets: 74it [00:00, 121.80it/s]creating rnd access train datasets: 90it [00:00, 130.73it/s]creating rnd access train datasets: 107it [00:00, 141.12it/s]creating rnd access train datasets: 122it [00:01, 108.02it/s]creating rnd access train datasets: 151it [00:01, 150.23it/s]creating rnd access train datasets: 169it [00:01, 151.76it/s]creating rnd access train datasets: 187it [00:01, 157.16it/s]creating rnd access train datasets: 204it [00:01, 159.43it/s]creating rnd access train datasets: 221it [00:01, 161.70it/s]creating rnd access train datasets: 238it [00:01, 160.97it/s]creating rnd access train datasets: 255it [00:01, 158.61it/s]creating rnd access train datasets: 255it [00:01, 149.49it/s]creating rnd access train datasets: 271it [00:02, 149.32it/s]creating rnd access train datasets: 287it [00:02, 152.26it/s]creating rnd access train datasets: 304it [00:02, 155.65it/s]creating rnd access train datasets: 320it [00:02, 156.66it/s]creating rnd access train datasets: 337it [00:02, 158.33it/s]creating rnd access train datasets: 354it [00:02, 161.15it/s]creating rnd access train datasets: 371it [00:02, 159.42it/s]creating rnd access train datasets: 387it [00:02, 155.02it/s]creating rnd access train datasets: 403it [00:02, 154.78it/s]creating rnd access train datasets: 420it [00:03, 159.05it/s]creating rnd access train datasets: 438it [00:03, 163.29it/s]creating rnd access train datasets: 455it [00:03, 162.02it/s]creating rnd access train datasets: 472it [00:03, 160.66it/s]creating rnd access train datasets: 489it [00:03, 157.68it/s]creating rnd access train datasets: 505it [00:03, 153.50it/s]creating rnd access 151.37it/s]creating rnd access train datasets: 270it [00:02, 149.88it/s]creating rnd access train datasets: 286it [00:02, 152.63it/s]creating rnd access train datasets: 303it [00:02, 156.48it/s]creating rnd access train datasets: 319it [00:02, 157.26it/s]creating rnd access train datasets: 336it [00:02, 158.66it/s]creating rnd access train datasets: 353it [00:02, 160.54it/s]creating rnd access train datasets: 370it [00:02, 159.85it/s]creating rnd access train datasets: 387it [00:02, 154.99it/s]creating rnd access train datasets: 403it [00:02, 154.76it/s]creating rnd access train datasets: 420it [00:03, 159.09it/s]creating rnd access train datasets: 438it [00:03, 163.29it/s]creating rnd access train datasets: 455it [00:03, 162.04it/s]creating rnd access train datasets: 472it [00:03, 160.45it/s]creating rnd access train datasets: 489it [00:03, 157.76it/s]creating rnd access train datasets: 505it [00:03, 153.56it/s]creating rnd access train datasets: 521it [00:03, 154.03it/s]creating rnd access 151.42it/s]creating rnd access train datasets: 270it [00:02, 149.92it/s]creating rnd access train datasets: 286it [00:02, 152.66it/s]creating rnd access train datasets: 303it [00:02, 156.59it/s]creating rnd access train datasets: 319it [00:02, 157.25it/s]creating rnd access train datasets: 336it [00:02, 158.65it/s]creating rnd access train datasets: 353it [00:02, 160.67it/s]creating rnd access train datasets: 370it [00:02, 159.66it/s]creating rnd access train datasets: 387it [00:02, 155.10it/s]creating rnd access train datasets: 403it [00:02, 154.83it/s]creating rnd access train datasets: 420it [00:03, 158.95it/s]creating rnd access train datasets: 438it [00:03, 163.17it/s]creating rnd access train datasets: 455it [00:03, 161.95it/s]creating rnd access train datasets: 472it [00:03, 160.74it/s]creating rnd access train datasets: 489it [00:03, 157.62it/s]creating rnd access train datasets: 505it [00:03, 153.46it/s]creating rnd access train datasets: 521it [00:03, 154.07it/s]creating rnd access 151.12it/s]creating rnd access train datasets: 271it [00:02, 150.40it/s]creating rnd access train datasets: 287it [00:02, 152.96it/s]creating rnd access train datasets: 304it [00:02, 156.02it/s]creating rnd access train datasets: 320it [00:02, 156.78it/s]creating rnd access train datasets: 337it [00:02, 158.53it/s]creating rnd access train datasets: 354it [00:02, 161.27it/s]creating rnd access train datasets: 371it [00:02, 159.63it/s]creating rnd access train datasets: 388it [00:02, 153.81it/s]creating rnd access train datasets: 405it [00:02, 155.75it/s]creating rnd access train datasets: 422it [00:03, 159.44it/s]creating rnd access train datasets: 440it [00:03, 163.47it/s]creating rnd access train datasets: 457it [00:03, 161.99it/s]creating rnd access train datasets: 474it [00:03, 160.31it/s]creating rnd access train datasets: 491it [00:03, 157.41it/s]creating rnd access train datasets: 507it [00:03, 153.41it/s]creating rnd access train datasets: 523it [00:03, 154.33it/s]creating rnd access train datasets: 538it [00:03, 157.08it/s]creating rnd access train datasets: 554it [00:03, 157.11it/s]creating rnd access train datasets: 571it [00:03, 158.11it/s]creating rnd access train datasets: 587it [00:04, 158.02it/s]creating rnd access train datasets: 604it [00:04, 159.79it/s]creating rnd access train datasets: 621it [00:04, 161.66it/s]creating rnd access train datasets: 638it [00:04, 157.25it/s]creating rnd access train datasets: 655it [00:04, 159.41it/s]creating rnd access train datasets: 673it [00:04, 163.04it/s]creating rnd access train datasets: 681it [00:04, 146.58it/s]
 train datasets: 538it [00:03, 157.11it/s]creating rnd access train datasets: 554it [00:03, 157.14it/s]creating rnd access train datasets: 571it [00:03, 158.24it/s]creating rnd access train datasets: 587it [00:04, 158.10it/s]creating rnd access train datasets: 604it [00:04, 159.75it/s]creating rnd access train datasets: 621it [00:04, 161.62it/s]creating rnd access train datasets: 638it [00:04, 157.22it/s]creating rnd access train datasets: 655it [00:04, 159.49it/s]creating rnd access train datasets: 673it [00:04, 163.11it/s]creating rnd access train datasets: 681it [00:04, 146.58it/s]
 train datasets: 540it [00:03, 157.39it/s]creating rnd access train datasets: 556it [00:03, 157.01it/s]creating rnd access train datasets: 572it [00:03, 157.57it/s]creating rnd access train datasets: 589it [00:04, 158.65it/s]creating rnd access train datasets: 606it [00:04, 159.51it/s]creating rnd access train datasets: 623it [00:04, 161.67it/s]creating rnd access train datasets: 640it [00:04, 157.00it/s]creating rnd access train datasets: 657it [00:04, 160.39it/s]creating rnd access train datasets: 675it [00:04, 163.41it/s]creating rnd access train datasets: 681it [00:04, 146.58it/s]
 train datasets: 521it [00:03, 153.99it/s]creating rnd access train datasets: 538it [00:03, 157.06it/s]creating rnd access train datasets: 554it [00:03, 157.01it/s]creating rnd access train datasets: 571it [00:03, 158.23it/s]creating rnd access train datasets: 587it [00:04, 158.11it/s]creating rnd access train datasets: 604it [00:04, 159.74it/s]creating rnd access train datasets: 621it [00:04, 161.50it/s]creating rnd access train datasets: 638it [00:04, 157.14it/s]creating rnd access train datasets: 655it [00:04, 159.55it/s]creating rnd access train datasets: 673it [00:04, 163.15it/s]creating rnd access train datasets: 681it [00:04, 146.57it/s]
creating streaming train datasets: 0it [00:00, ?it/s]creating streaming train datasets: 16it [00:00, 156.90it/s]creating streaming train datasets: 32it [00:00, 135.69it/s]creating streaming train datasets: 47it [00:00, 136.05it/s]creating streaming train datasets: 65it [00:00, 150.45it/s]creating streaming train datasets: 82it [00:00, 155.09it/s]creating streaming train datasets: 101it [00:00, 165.44it/s]creating streaming train datasets: 118it [00:00, 160.39it/s]creating streaming train datasets: 139it [00:00, 172.11it/s]creating streaming train datasets: 157it [00:01, 159.01it/s]creating streaming train datasets: 174it [00:01, 149.74it/s]creating streaming train datasets: 195it [00:01, 165.37it/s]creating streaming train datasets: 214it [00:01, 171.68it/s]creating streaming train datasets: 233it [00:01, 176.05it/s]creating streaming train datasets: 252it [00:01, 178.27it/s]creating streaming train datasets: 271it [00:01, 181.50it/s]creating streaming train datasets: 290it [00:01, 152.61it/screating streaming train datasets: 0it [00:00, ?it/s]creating streaming train datasets: 16it [00:00, 155.31it/s]creating streaming train datasets: 32it [00:00, 134.40it/s]creating streaming train datasets: 47it [00:00, 135.98it/s]creating streaming train datasets: 65it [00:00, 149.77it/s]creating streaming train datasets: 81it [00:00, 152.10it/s]creating streaming train datasets: 101it [00:00, 166.82it/s]creating streaming train datasets: 118it [00:00, 162.62it/s]creating streaming train datasets: 139it [00:00, 172.20it/s]creating streaming train datasets: 157it [00:01, 159.02it/s]creating streaming train datasets: 174it [00:01, 149.86it/s]creating streaming train datasets: 195it [00:01, 165.29it/s]creating streaming train datasets: 214it [00:01, 171.62it/s]creating streaming train datasets: 233it [00:01, 176.14it/s]creating streaming train datasets: 251it [00:01, 177.22it/s]creating streaming train datasets: 271it [00:01, 181.80it/s]creating streaming train datasets: 290it [00:01, 152.84it/screating streaming train datasets: 0it [00:00, ?it/s]creating streaming train datasets: 16it [00:00, 156.02it/s]creating streaming train datasets: 32it [00:00, 135.39it/s]creating streaming train datasets: 47it [00:00, 136.16it/s]creating streaming train datasets: 65it [00:00, 150.20it/s]creating streaming train datasets: 82it [00:00, 154.78it/s]creating streaming train datasets: 101it [00:00, 165.60it/s]creating streaming train datasets: 118it [00:00, 161.73it/s]creating streaming train datasets: 139it [00:00, 171.62it/s]creating streaming train datasets: 157it [00:01, 158.73it/s]creating streaming train datasets: 174it [00:01, 149.61it/s]creating streaming train datasets: 195it [00:01, 165.30it/s]creating streaming train datasets: 214it [00:01, 171.53it/s]creating streaming train datasets: 233it [00:01, 176.01it/s]creating streaming train datasets: 252it [00:01, 178.17it/s]creating streaming train datasets: 271it [00:01, 181.37it/s]creating streaming train datasets: 290it [00:01, 152.59it/screating streaming train datasets: 0it [00:00, ?it/s]creating streaming train datasets: 16it [00:00, 156.14it/s]creating streaming train datasets: 32it [00:00, 135.37it/s]creating streaming train datasets: 47it [00:00, 136.12it/s]creating streaming train datasets: 65it [00:00, 150.39it/s]creating streaming train datasets: 81it [00:00, 151.57it/s]creating streaming train datasets: 101it [00:00, 166.51it/s]creating streaming train datasets: 118it [00:00, 162.13it/s]creating streaming train datasets: 139it [00:00, 172.02it/s]creating streaming train datasets: 157it [00:01, 159.01it/s]creating streaming train datasets: 174it [00:01, 149.76it/s]creating streaming train datasets: 195it [00:01, 165.40it/s]creating streaming train datasets: 214it [00:01, 171.71it/s]creating streaming train datasets: 233it [00:01, 176.13it/s]creating streaming train datasets: 252it [00:01, 178.26it/s]creating streaming train datasets: 271it [00:01, 181.49it/s]creating streaming train datasets: 290it [00:01, 152.56it/s]creating streaming train datasets: 307it [00:01, 146.67it/s]creating streaming train datasets: 323it [00:02, 149.81it/s]creating streaming train datasets: 343it [00:02, 158.84it/s]creating streaming train datasets: 360it [00:02, 160.38it/s]creating streaming train datasets: 381it [00:02, 173.73it/s]creating streaming train datasets: 399it [00:02, 157.49it/s]creating streaming train datasets: 416it [00:02, 155.77it/s]creating streaming train datasets: 436it [00:02, 160.86it/s]creating streaming train datasets: 454it [00:02, 165.42it/s]creating streaming train datasets: 471it [00:02, 165.09it/s]creating streaming train datasets: 488it [00:03, 164.60it/s]creating streaming train datasets: 505it [00:03, 164.18it/s]creating streaming train datasets: 522it [00:03, 164.26it/s]creating streaming train datasets: 539it [00:03, 143.97it/s]creating streaming train datasets: 558it [00:03, 155.39it/s]creating streaming train datasets: 575it [00:03, 142.89it/s]creating streaming train datasets: 591it [00:0]creating streaming train datasets: 307it [00:01, 146.84it/s]creating streaming train datasets: 323it [00:02, 149.94it/s]creating streaming train datasets: 343it [00:02, 159.13it/s]creating streaming train datasets: 360it [00:02, 160.33it/s]creating streaming train datasets: 381it [00:02, 173.74it/s]creating streaming train datasets: 399it [00:02, 157.45it/s]creating streaming train datasets: 416it [00:02, 155.72it/s]creating streaming train datasets: 436it [00:02, 161.19it/s]creating streaming train datasets: 453it [00:02, 163.48it/s]creating streaming train datasets: 470it [00:02, 162.14it/s]creating streaming train datasets: 488it [00:03, 164.21it/s]creating streaming train datasets: 505it [00:03, 165.68it/s]creating streaming train datasets: 522it [00:03, 165.40it/s]creating streaming train datasets: 539it [00:03, 144.68it/s]creating streaming train datasets: 558it [00:03, 155.78it/s]creating streaming train datasets: 575it [00:03, 143.25it/s]creating streaming train datasets: 591it [00:0]creating streaming train datasets: 307it [00:01, 146.64it/s]creating streaming train datasets: 323it [00:02, 149.83it/s]creating streaming train datasets: 343it [00:02, 159.14it/s]creating streaming train datasets: 360it [00:02, 160.31it/s]creating streaming train datasets: 381it [00:02, 173.67it/s]creating streaming train datasets: 399it [00:02, 157.46it/s]creating streaming train datasets: 416it [00:02, 155.84it/s]creating streaming train datasets: 436it [00:02, 161.15it/s]creating streaming train datasets: 454it [00:02, 165.28it/s]creating streaming train datasets: 471it [00:02, 164.93it/s]creating streaming train datasets: 488it [00:03, 164.56it/s]creating streaming train datasets: 505it [00:03, 164.15it/s]creating streaming train datasets: 522it [00:03, 164.33it/s]creating streaming train datasets: 539it [00:03, 143.84it/s]creating streaming train datasets: 558it [00:03, 155.37it/s]creating streaming train datasets: 575it [00:03, 142.90it/s]creating streaming train datasets: 591it [00:0]creating streaming train datasets: 307it [00:01, 146.66it/s]creating streaming train datasets: 323it [00:02, 149.72it/s]creating streaming train datasets: 343it [00:02, 159.04it/s]creating streaming train datasets: 360it [00:02, 160.34it/s]creating streaming train datasets: 381it [00:02, 173.65it/s]creating streaming train datasets: 399it [00:02, 157.49it/s]creating streaming train datasets: 416it [00:02, 155.74it/s]creating streaming train datasets: 436it [00:02, 160.18it/s]creating streaming train datasets: 455it [00:02, 166.44it/s]creating streaming train datasets: 472it [00:02, 164.26it/s]creating streaming train datasets: 489it [00:03, 165.85it/s]creating streaming train datasets: 506it [00:03, 165.20it/s]creating streaming train datasets: 523it [00:03, 164.29it/s]creating streaming train datasets: 540it [00:03, 144.18it/s]creating streaming train datasets: 559it [00:03, 152.37it/s]creating streaming train datasets: 575it [00:03, 142.91it/s]creating streaming train datasets: 591it [00:03, 146.30it/s]creating streaming train datasets: 610it [00:03, 155.71it/s]creating streaming train datasets: 627it [00:03, 158.11it/s]creating streaming train datasets: 645it [00:04, 160.42it/s]creating streaming train datasets: 666it [00:04, 172.78it/s]creating streaming train datasets: 681it [00:04, 159.66it/s]
3, 146.49it/s]creating streaming train datasets: 610it [00:03, 155.67it/s]creating streaming train datasets: 627it [00:03, 158.05it/s]creating streaming train datasets: 645it [00:04, 160.39it/s]creating streaming train datasets: 666it [00:04, 172.77it/s]creating streaming train datasets: 681it [00:04, 159.65it/s]
3, 146.26it/s]creating streaming train datasets: 610it [00:03, 155.46it/s]creating streaming train datasets: 627it [00:03, 158.00it/s]creating streaming train datasets: 645it [00:04, 160.37it/s]creating streaming train datasets: 666it [00:04, 172.68it/s]creating streaming train datasets: 681it [00:04, 159.67it/s]
3, 146.25it/s]creating streaming train datasets: 610it [00:03, 155.53it/s]creating streaming train datasets: 627it [00:03, 158.14it/s]creating streaming train datasets: 645it [00:04, 160.33it/s]creating streaming train datasets: 666it [00:04, 172.55it/s]creating streaming train datasets: 681it [00:04, 159.63it/s]
creating streaming val datasets: 0it [00:00, ?it/s]creating streaming val datasets: 14it [00:00, 133.81it/s]creating streaming val datasets: 30it [00:00, 145.28it/s]creating streaming val datasets: 46it [00:00, 147.30it/s]creating streaming val datasets: 61it [00:00, 145.82it/s]creating streaming val datasets: 76it [00:00, 139.46it/s]creating streaming val datasets: 90it [00:00, 138.98it/s]creating streaming val datasets: 105it [00:00, 142.22it/s]creating streaming val datasets: 121it [00:00, 147.39it/s]creating streaming val datasets: 128it [00:00, 143.80it/s]
creating streaming val datasets: 0it [00:00, ?it/s]creating streaming val datasets: 14it [00:00, 133.65it/s]creating streaming val datasets: 30it [00:00, 145.25it/s]creating streaming val datasets: 46it [00:00, 147.40it/s]creating streaming val datasets: 61it [00:00, 145.78it/s]creating streaming val datasets: 76it [00:00, 139.20it/s]creating streaming val datasets: 90it [00:00, 139.06it/s]creating streaming val datasets: 105it [00:00, 142.27it/s]creating streaming val datasets: 121it [00:00, 147.43it/s]creating streaming val datasets: 128it [00:00, 143.79it/s]
creating streaming val datasets: 0it [00:00, ?it/s]creating streaming val datasets: 14it [00:00, 133.82it/s]creating streaming val datasets: 30it [00:00, 145.27it/s]creating streaming val datasets: 46it [00:00, 147.38it/s]creating streaming val datasets: 61it [00:00, 145.79it/s]creating streaming val datasets: 76it [00:00, 139.51it/s]creating streaming val datasets: 90it [00:00, 138.90it/s]creating streaming val datasets: 105it [00:00, 142.18it/s]creating streaming val datasets: 121it [00:00, 147.40it/s]creating streaming val datasets: 128it [00:00, 143.77it/s]
creating streaming val datasets: 0it [00:00, ?it/s]creating streaming val datasets: 14it [00:00, 133.99it/s]creating streaming val datasets: 30it [00:00, 145.16it/s]creating streaming val datasets: 46it [00:00, 147.47it/s]creating streaming val datasets: 61it [00:00, 145.77it/s]creating streaming val datasets: 76it [00:00, 139.47it/s]creating streaming val datasets: 90it [00:00, 139.02it/s]creating streaming val datasets: 105it [00:00, 142.24it/s]creating streaming val datasets: 121it [00:00, 147.35it/s]creating streaming val datasets: 128it [00:00, 143.78it/s]
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /leonardo/home/userexternal/ychen004/ssm-event-gen4/ssms_event_cameras/nu0t4ndp/checkpoints exists and is not empty.
Restoring states from the checkpoint path at /leonardo/home/userexternal/ychen004/ssm-event-gen4/ssms_event_cameras/nu0t4ndp/checkpoints/epoch=000-step=280000-val_AP=0.39.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name           | Type          | Params | Mode 
---------------------------------------------------------
0 | mdl            | YoloXDetector | 13.3 M | train
1 | mdl.backbone   | RNNDetector   | 10.7 M | train
2 | mdl.fpn        | YOLOPAFPN     | 1.6 M  | train
3 | mdl.yolox_head | YOLOXHead     | 1.1 M  | train
---------------------------------------------------------
13.3 M    Trainable params
0         Non-trainable params
13.3 M    Total params
53.291    Total estimated model params size (MB)
441       Modules in train mode
0         Modules in eval mode
Restored all states from the checkpoint at /leonardo/home/userexternal/ychen004/ssm-event-gen4/ssms_event_cameras/nu0t4ndp/checkpoints/epoch=000-step=280000-val_AP=0.39.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/autograd/__init__.py:266: UserWarning:

Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1, 96, 1, 1], strides() = [96, 1, 96, 96]
bucket_view.sizes() = [1, 96, 1, 1], strides() = [96, 1, 1, 1] (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/torch/csrc/distributed/c10d/reducer.cpp:322.)

/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1, 96, 1, 1], strides() = [96, 1, 96, 96]
bucket_view.sizes() = [1, 96, 1, 1], strides() = [96, 1, 1, 1] (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1, 96, 1, 1], strides() = [96, 1, 96, 96]
bucket_view.sizes() = [1, 96, 1, 1], strides() = [96, 1, 1, 1] (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1, 96, 1, 1], strides() = [96, 1, 96, 96]
bucket_view.sizes() = [1, 96, 1, 1], strides() = [96, 1, 1, 1] (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch 0, global step 290000: 'val/AP' reached 0.39572 (best 0.39572), saving model to '/leonardo/home/userexternal/ychen004/ssm-event-gen4/ssms_event_cameras/nu0t4ndp/checkpoints/epoch=000-step=290000-val_AP=0.40.ckpt' as top 1
Epoch 0, global step 300000: 'val/AP' was not in top 1
Epoch 0, global step 310000: 'val/AP' was not in top 1
Epoch 0, global step 320000: 'val/AP' was not in top 1
Epoch 0, global step 330000: 'val/AP' was not in top 1
Epoch 0, global step 340000: 'val/AP' reached 0.39632 (best 0.39632), saving model to '/leonardo/home/userexternal/ychen004/ssm-event-gen4/ssms_event_cameras/nu0t4ndp/checkpoints/epoch=000-step=340000-val_AP=0.40.ckpt' as top 1
Epoch 0, global step 350000: 'val/AP' was not in top 1
Epoch 0, global step 360000: 'val/AP' reached 0.39832 (best 0.39832), saving model to '/leonardo/home/userexternal/ychen004/ssm-event-gen4/ssms_event_cameras/nu0t4ndp/checkpoints/epoch=000-step=360000-val_AP=0.40.ckpt' as top 1
Epoch 0, global step 370000: 'val/AP' was not in top 1
Epoch 0, global step 380000: 'val/AP' was not in top 1
Epoch 0, global step 390000: 'val/AP' was not in top 1
Epoch 0, global step 400000: 'val/AP' was not in top 1
`Trainer.fit` stopped: `max_steps=400001` reached.
wandb: 
wandb: Run history:
wandb:                epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:  train/cls_loss_step █▅▇▄▂▃▃█▃▄▄▃▃▅▄▄▃▂▇▄▁▃▃▄▅▆▆▆▅▂▄▃▅▃▄▆▃▄▇▄
wandb: train/conf_loss_step ▇▃▇▃▄▄▃█▂▃▃▂▂▄▃▃▂▃▆▃▁▂▃▅▅▄▅▄▄▂▃▃▅▂▃▇▂▃█▄
wandb:  train/iou_loss_step █▅▇▅▂▃▂█▂▄▄▃▂▄▅▃▂▁█▃▁▄▃▃▆▅▆▆▆▂▄▃▅▂▅▇▂▅▆▃
wandb:   train/l1_loss_step ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/loss_step █▄▇▄▃▄▃█▂▄▄▂▂▄▄▃▂▂▆▃▁▃▃▄▅▅▅▅▅▂▄▃▅▂▄▇▂▄▇▃
wandb:    train/num_fg_step ▁▂▂▄▄▅▅▃▆▅▆▆▅▆▃▇▇█▁▅▆▆▅▄▃▂▃▃▂▆▆▄▂▆▄▂▅▄▂▅
wandb:  trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:               val/AP ▇▄▁▆▄▇▆█▇▇▆▇
wandb:            val/AP_50 █▂▁▅▂▄▄█▆▅▆▆
wandb:            val/AP_75 ▇▄▁▇▄▇▇█▇▇▆▇
wandb:             val/AP_L █▇▁▆▆█▄█▇▇▆▇
wandb:             val/AP_M █▃▁▅▄▇▅▆▆▆▄▅
wandb:             val/AP_S ▃▁▂▅▅▄▅█▆▆▆▇
wandb: 
wandb: Run summary:
wandb:                epoch 0
wandb:        learning_rate 0.0
wandb:  train/cls_loss_step 0.4194
wandb: train/conf_loss_step 0.75539
wandb:  train/iou_loss_step 1.36607
wandb:   train/l1_loss_step 0.0
wandb:      train/loss_step 2.54087
wandb:    train/num_fg_step 7.37429
wandb:  trainer/global_step 400002
wandb:               val/AP 0.39613
wandb:            val/AP_50 0.67091
wandb:            val/AP_75 0.40761
wandb:             val/AP_L 0.48603
wandb:             val/AP_M 0.43919
wandb:             val/AP_S 0.28671
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/ychen004/ssm-event-gen4/wandb/offline-run-20250629_111852-nu0t4ndp
wandb: Find logs at: ./wandb/offline-run-20250629_111852-nu0t4ndp/logs
wandb: WARNING Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric
wandb: WARNING (User provided step: 284999 is less than current step: 285000. Dropping entry: {'train/loss_step': 3.266373872756958, 'train/iou_loss_step': 1.7226094007492065, 'train/conf_loss_step': 1.005843162536621, 'train/cls_loss_step': 0.5379213690757751, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 6.447358131408691, 'epoch': 0, 'trainer/global_step': 284999, '_timestamp': 1751193731.7221174}).
wandb: WARNING (User provided step: 289999 is less than current step: 290000. Dropping entry: {'train/loss_step': 2.285046339035034, 'train/iou_loss_step': 1.2244410514831543, 'train/conf_loss_step': 0.6639657020568848, 'train/cls_loss_step': 0.3966395854949951, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.657283782958984, 'epoch': 0, 'trainer/global_step': 289999, '_timestamp': 1751198680.0057518}).
wandb: WARNING (User provided step: 289999 is less than current step: 290002. Dropping entry: {'val/AP': 0.3957176157231808, 'val/AP_50': 0.6743950705195522, 'val/AP_75': 0.4058460893104797, 'val/AP_S': 0.2791966380666473, 'val/AP_M': 0.4457394862448801, 'val/AP_L': 0.4882562426083783, 'epoch': 0, 'trainer/global_step': 289999, '_timestamp': 1751199244.3303137}).
wandb: WARNING (User provided step: 290000 is less than current step: 290002. Dropping entry: {'train/gradients': {'_type': 'plotly-file', 'sha256': 'da13c3d16ed1e78630d9cb796f8c3b6f3fc2701cdbc6b9bf70338802a56f39d7', 'size': 7784, 'path': 'media/plotly/train/gradients_290002_da13c3d16ed1e78630d9.plotly.json'}, 'trainer/global_step': 290000, '_timestamp': 1751199245.9542513}).
wandb: WARNING (User provided step: 294999 is less than current step: 295000. Dropping entry: {'train/loss_step': 2.3347556591033936, 'train/iou_loss_step': 1.2336161136627197, 'train/conf_loss_step': 0.7127668261528015, 'train/cls_loss_step': 0.38837283849716187, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.687675476074219, 'epoch': 0, 'trainer/global_step': 294999, '_timestamp': 1751204192.6943724}).
wandb: WARNING (User provided step: 299999 is less than current step: 300000. Dropping entry: {'train/loss_step': 2.443831443786621, 'train/iou_loss_step': 1.3676478862762451, 'train/conf_loss_step': 0.677911639213562, 'train/cls_loss_step': 0.3982720971107483, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.272745132446289, 'epoch': 0, 'trainer/global_step': 299999, '_timestamp': 1751209142.8133526}).
wandb: WARNING (User provided step: 299999 is less than current step: 300002. Dropping entry: {'val/AP': 0.3902989490975869, 'val/AP_50': 0.6639302498906472, 'val/AP_75': 0.39931480755376236, 'val/AP_S': 0.27460356436748135, 'val/AP_M': 0.4338133488468134, 'val/AP_L': 0.486445057905986, 'epoch': 0, 'trainer/global_step': 299999, '_timestamp': 1751209708.056903}).
wandb: WARNING (User provided step: 300000 is less than current step: 300002. Dropping entry: {'train/gradients': {'_type': 'plotly-file', 'sha256': 'da13c3d16ed1e78630d9cb796f8c3b6f3fc2701cdbc6b9bf70338802a56f39d7', 'size': 7784, 'path': 'media/plotly/train/gradients_300002_da13c3d16ed1e78630d9.plotly.json'}, 'trainer/global_step': 300000, '_timestamp': 1751209709.1066349}).
wandb: WARNING (User provided step: 304999 is less than current step: 305000. Dropping entry: {'train/loss_step': 2.48504376411438, 'train/iou_loss_step': 1.340014100074768, 'train/conf_loss_step': 0.7368305325508118, 'train/cls_loss_step': 0.40819913148880005, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.489663124084473, 'epoch': 0, 'trainer/global_step': 304999, '_timestamp': 1751214675.8410223}).
wandb: WARNING (User provided step: 309999 is less than current step: 310000. Dropping entry: {'train/loss_step': 2.929966449737549, 'train/iou_loss_step': 1.4796810150146484, 'train/conf_loss_step': 0.9792687296867371, 'train/cls_loss_step': 0.4710168242454529, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.10178279876709, 'epoch': 0, 'trainer/global_step': 309999, '_timestamp': 1751219638.674679}).
wandb: WARNING (User provided step: 309999 is less than current step: 310002. Dropping entry: {'val/AP': 0.3852024802582146, 'val/AP_50': 0.6627737040107897, 'val/AP_75': 0.39174542495848524, 'val/AP_S': 0.2775688173027273, 'val/AP_M': 0.4277793813454849, 'val/AP_L': 0.46635674987334624, 'epoch': 0, 'trainer/global_step': 309999, '_timestamp': 1751220204.9270816}).
wandb: WARNING (User provided step: 310000 is less than current step: 310002. Dropping entry: {'train/gradients': {'_type': 'plotly-file', 'sha256': 'da13c3d16ed1e78630d9cb796f8c3b6f3fc2701cdbc6b9bf70338802a56f39d7', 'size': 7784, 'path': 'media/plotly/train/gradients_310002_da13c3d16ed1e78630d9.plotly.json'}, 'trainer/global_step': 310000, '_timestamp': 1751220206.0903907}).
wandb: WARNING (User provided step: 314999 is less than current step: 315000. Dropping entry: {'train/loss_step': 2.4147777557373047, 'train/iou_loss_step': 1.3393504619598389, 'train/conf_loss_step': 0.6630567312240601, 'train/cls_loss_step': 0.4123706817626953, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.793319225311279, 'epoch': 0, 'trainer/global_step': 314999, '_timestamp': 1751225171.7800028}).
wandb: WARNING (User provided step: 319999 is less than current step: 320000. Dropping entry: {'train/loss_step': 2.152160882949829, 'train/iou_loss_step': 1.2135727405548096, 'train/conf_loss_step': 0.5509887933731079, 'train/cls_loss_step': 0.3875993490219116, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.739195346832275, 'epoch': 0, 'trainer/global_step': 319999, '_timestamp': 1751230120.6161163}).
wandb: WARNING (User provided step: 319999 is less than current step: 320002. Dropping entry: {'val/AP': 0.3944067667804446, 'val/AP_50': 0.6700831347508289, 'val/AP_75': 0.4059771051884797, 'val/AP_S': 0.28278396372387316, 'val/AP_M': 0.43853115107551466, 'val/AP_L': 0.48231409035156647, 'epoch': 0, 'trainer/global_step': 319999, '_timestamp': 1751230687.6217365}).
wandb: WARNING (User provided step: 320000 is less than current step: 320002. Dropping entry: {'train/gradients': {'_type': 'plotly-file', 'sha256': 'da13c3d16ed1e78630d9cb796f8c3b6f3fc2701cdbc6b9bf70338802a56f39d7', 'size': 7784, 'path': 'media/plotly/train/gradients_320002_da13c3d16ed1e78630d9.plotly.json'}, 'trainer/global_step': 320000, '_timestamp': 1751230688.9209926}).
wandb: WARNING (User provided step: 324999 is less than current step: 325000. Dropping entry: {'train/loss_step': 2.374933958053589, 'train/iou_loss_step': 1.3515394926071167, 'train/conf_loss_step': 0.6129793524742126, 'train/cls_loss_step': 0.41041505336761475, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.47515869140625, 'epoch': 0, 'trainer/global_step': 324999, '_timestamp': 1751235640.5315878}).
wandb: WARNING (User provided step: 329999 is less than current step: 330000. Dropping entry: {'train/loss_step': 2.2645792961120605, 'train/iou_loss_step': 1.266736388206482, 'train/conf_loss_step': 0.5607736706733704, 'train/cls_loss_step': 0.437069296836853, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.932999134063721, 'epoch': 0, 'trainer/global_step': 329999, '_timestamp': 1751240579.9183903}).
wandb: WARNING (User provided step: 329999 is less than current step: 330002. Dropping entry: {'val/AP': 0.391509515292921, 'val/AP_50': 0.6638394556335065, 'val/AP_75': 0.39970061424160874, 'val/AP_S': 0.282022224518897, 'val/AP_M': 0.43461339673301097, 'val/AP_L': 0.4828984339888125, 'epoch': 0, 'trainer/global_step': 329999, '_timestamp': 1751241145.555825}).
wandb: WARNING (User provided step: 330000 is less than current step: 330002. Dropping entry: {'train/gradients': {'_type': 'plotly-file', 'sha256': 'da13c3d16ed1e78630d9cb796f8c3b6f3fc2701cdbc6b9bf70338802a56f39d7', 'size': 7784, 'path': 'media/plotly/train/gradients_330002_da13c3d16ed1e78630d9.plotly.json'}, 'trainer/global_step': 330000, '_timestamp': 1751241146.631095}).
wandb: WARNING (User provided step: 334999 is less than current step: 335000. Dropping entry: {'train/loss_step': 2.5711560249328613, 'train/iou_loss_step': 1.3248440027236938, 'train/conf_loss_step': 0.8253540396690369, 'train/cls_loss_step': 0.4209580421447754, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.67479133605957, 'epoch': 0, 'trainer/global_step': 334999, '_timestamp': 1751246022.6592193}).
wandb: WARNING (User provided step: 339999 is less than current step: 340000. Dropping entry: {'train/loss_step': 2.5756211280822754, 'train/iou_loss_step': 1.4138705730438232, 'train/conf_loss_step': 0.7475389242172241, 'train/cls_loss_step': 0.4142119288444519, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.257901668548584, 'epoch': 0, 'trainer/global_step': 339999, '_timestamp': 1751250883.8138895}).
wandb: WARNING (User provided step: 339999 is less than current step: 340002. Dropping entry: {'val/AP': 0.39631972091432394, 'val/AP_50': 0.6684929534358247, 'val/AP_75': 0.4063102512733925, 'val/AP_S': 0.2815146051917164, 'val/AP_M': 0.4434008092775779, 'val/AP_L': 0.4882383219390205, 'epoch': 0, 'trainer/global_step': 339999, '_timestamp': 1751251435.1684449}).
wandb: WARNING (User provided step: 340000 is less than current step: 340002. Dropping entry: {'train/gradients': {'_type': 'plotly-file', 'sha256': 'da13c3d16ed1e78630d9cb796f8c3b6f3fc2701cdbc6b9bf70338802a56f39d7', 'size': 7784, 'path': 'media/plotly/train/gradients_340002_da13c3d16ed1e78630d9.plotly.json'}, 'trainer/global_step': 340000, '_timestamp': 1751251436.6618829}).
wandb: WARNING (User provided step: 344999 is less than current step: 345000. Dropping entry: {'train/loss_step': 2.257380723953247, 'train/iou_loss_step': 1.2798280715942383, 'train/conf_loss_step': 0.5757114887237549, 'train/cls_loss_step': 0.40184131264686584, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.734001636505127, 'epoch': 0, 'trainer/global_step': 344999, '_timestamp': 1751256321.7391195}).
wandb: WARNING (User provided step: 349999 is less than current step: 350000. Dropping entry: {'train/loss_step': 2.1090989112854004, 'train/iou_loss_step': 1.1470558643341064, 'train/conf_loss_step': 0.5999742150306702, 'train/cls_loss_step': 0.36206871271133423, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.931905269622803, 'epoch': 0, 'trainer/global_step': 349999, '_timestamp': 1751261161.0837264}).
wandb: WARNING (User provided step: 349999 is less than current step: 350002. Dropping entry: {'val/AP': 0.394274165642347, 'val/AP_50': 0.6672381094898031, 'val/AP_75': 0.4063595319385295, 'val/AP_S': 0.2835531002986176, 'val/AP_M': 0.4371549315797133, 'val/AP_L': 0.47494691595839644, 'epoch': 0, 'trainer/global_step': 349999, '_timestamp': 1751261712.1577199}).
wandb: WARNING (User provided step: 350000 is less than current step: 350002. Dropping entry: {'train/gradients': {'_type': 'plotly-file', 'sha256': 'da13c3d16ed1e78630d9cb796f8c3b6f3fc2701cdbc6b9bf70338802a56f39d7', 'size': 7784, 'path': 'media/plotly/train/gradients_350002_da13c3d16ed1e78630d9.plotly.json'}, 'trainer/global_step': 350000, '_timestamp': 1751261713.3045619}).
wandb: WARNING (User provided step: 354999 is less than current step: 355000. Dropping entry: {'train/loss_step': 2.2108852863311768, 'train/iou_loss_step': 1.235521674156189, 'train/conf_loss_step': 0.5886395573616028, 'train/cls_loss_step': 0.3867240846157074, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.943580150604248, 'epoch': 0, 'trainer/global_step': 354999, '_timestamp': 1751266636.2845478}).
wandb: WARNING (User provided step: 359999 is less than current step: 360000. Dropping entry: {'train/loss_step': 2.382230758666992, 'train/iou_loss_step': 1.3128310441970825, 'train/conf_loss_step': 0.681692361831665, 'train/cls_loss_step': 0.38770729303359985, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.512636661529541, 'epoch': 0, 'trainer/global_step': 359999, '_timestamp': 1751271552.6588311}).
wandb: WARNING (User provided step: 359999 is less than current step: 360002. Dropping entry: {'val/AP': 0.39832069661779, 'val/AP_50': 0.6746767468259625, 'val/AP_75': 0.40896909430669676, 'val/AP_S': 0.28934768537379035, 'val/AP_M': 0.4418348662824425, 'val/AP_L': 0.48968469694857203, 'epoch': 0, 'trainer/global_step': 359999, '_timestamp': 1751272106.3044431}).
wandb: WARNING (User provided step: 360000 is less than current step: 360002. Dropping entry: {'train/gradients': {'_type': 'plotly-file', 'sha256': 'da13c3d16ed1e78630d9cb796f8c3b6f3fc2701cdbc6b9bf70338802a56f39d7', 'size': 7784, 'path': 'media/plotly/train/gradients_360002_da13c3d16ed1e78630d9.plotly.json'}, 'trainer/global_step': 360000, '_timestamp': 1751272107.7752442}).
wandb: WARNING (User provided step: 364999 is less than current step: 365000. Dropping entry: {'train/loss_step': 2.3939778804779053, 'train/iou_loss_step': 1.293949007987976, 'train/conf_loss_step': 0.7075212001800537, 'train/cls_loss_step': 0.3925076723098755, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.587393760681152, 'epoch': 0, 'trainer/global_step': 364999, '_timestamp': 1751277033.1438084}).
wandb: WARNING (User provided step: 369999 is less than current step: 370000. Dropping entry: {'train/loss_step': 2.334831714630127, 'train/iou_loss_step': 1.3016027212142944, 'train/conf_loss_step': 0.6335070729255676, 'train/cls_loss_step': 0.39972198009490967, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.610613822937012, 'epoch': 0, 'trainer/global_step': 369999, '_timestamp': 1751282020.766178}).
wandb: WARNING (User provided step: 369999 is less than current step: 370002. Dropping entry: {'val/AP': 0.39621918690642144, 'val/AP_50': 0.6712914756775133, 'val/AP_75': 0.40712816824089415, 'val/AP_S': 0.28499605000944395, 'val/AP_M': 0.44016720182957275, 'val/AP_L': 0.4854292358367377, 'epoch': 0, 'trainer/global_step': 369999, '_timestamp': 1751282574.3765748}).
wandb: WARNING (User provided step: 370000 is less than current step: 370002. Dropping entry: {'train/gradients': {'_type': 'plotly-file', 'sha256': 'da13c3d16ed1e78630d9cb796f8c3b6f3fc2701cdbc6b9bf70338802a56f39d7', 'size': 7784, 'path': 'media/plotly/train/gradients_370002_da13c3d16ed1e78630d9.plotly.json'}, 'trainer/global_step': 370000, '_timestamp': 1751282575.6106725}).
wandb: WARNING (User provided step: 374999 is less than current step: 375000. Dropping entry: {'train/loss_step': 2.99747896194458, 'train/iou_loss_step': 1.5069278478622437, 'train/conf_loss_step': 1.0721875429153442, 'train/cls_loss_step': 0.4183635115623474, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.425400733947754, 'epoch': 0, 'trainer/global_step': 374999, '_timestamp': 1751287586.2173853}).
wandb: WARNING (User provided step: 379999 is less than current step: 380000. Dropping entry: {'train/loss_step': 2.2732315063476562, 'train/iou_loss_step': 1.3239208459854126, 'train/conf_loss_step': 0.5465692281723022, 'train/cls_loss_step': 0.402741402387619, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.7617902755737305, 'epoch': 0, 'trainer/global_step': 379999, '_timestamp': 1751292689.3115895}).
wandb: WARNING (User provided step: 379999 is less than current step: 380002. Dropping entry: {'val/AP': 0.3959673581972383, 'val/AP_50': 0.6699928244829401, 'val/AP_75': 0.40599204649181964, 'val/AP_S': 0.28595643854007774, 'val/AP_M': 0.44123877358173574, 'val/AP_L': 0.48725828659915615, 'epoch': 0, 'trainer/global_step': 379999, '_timestamp': 1751293246.0527399}).
wandb: WARNING (User provided step: 380000 is less than current step: 380002. Dropping entry: {'train/gradients': {'_type': 'plotly-file', 'sha256': 'da13c3d16ed1e78630d9cb796f8c3b6f3fc2701cdbc6b9bf70338802a56f39d7', 'size': 7784, 'path': 'media/plotly/train/gradients_380002_da13c3d16ed1e78630d9.plotly.json'}, 'trainer/global_step': 380000, '_timestamp': 1751293247.2597678}).
wandb: WARNING (User provided step: 384999 is less than current step: 385000. Dropping entry: {'train/loss_step': 2.497044563293457, 'train/iou_loss_step': 1.3852100372314453, 'train/conf_loss_step': 0.6828135848045349, 'train/cls_loss_step': 0.4290211498737335, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.580538749694824, 'epoch': 0, 'trainer/global_step': 384999, '_timestamp': 1751298398.1620543}).
wandb: WARNING (User provided step: 389999 is less than current step: 390000. Dropping entry: {'train/loss_step': 2.419713258743286, 'train/iou_loss_step': 1.3878108263015747, 'train/conf_loss_step': 0.6273537874221802, 'train/cls_loss_step': 0.40454864501953125, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.3736653327941895, 'epoch': 0, 'trainer/global_step': 389999, '_timestamp': 1751303614.8015943}).
wandb: WARNING (User provided step: 389999 is less than current step: 390002. Dropping entry: {'val/AP': 0.3938681100396898, 'val/AP_50': 0.6708440191482286, 'val/AP_75': 0.40398749485945373, 'val/AP_S': 0.28465484665109164, 'val/AP_M': 0.4365630676661132, 'val/AP_L': 0.48263144034419725, 'epoch': 0, 'trainer/global_step': 389999, '_timestamp': 1751304263.8757274}).
wandb: WARNING (User provided step: 390000 is less than current step: 390002. Dropping entry: {'train/gradients': {'_type': 'plotly-file', 'sha256': 'da13c3d16ed1e78630d9cb796f8c3b6f3fc2701cdbc6b9bf70338802a56f39d7', 'size': 7784, 'path': 'media/plotly/train/gradients_390002_da13c3d16ed1e78630d9.plotly.json'}, 'trainer/global_step': 390000, '_timestamp': 1751304265.2591114}).
wandb: WARNING (User provided step: 394999 is less than current step: 395000. Dropping entry: {'train/loss_step': 2.193453550338745, 'train/iou_loss_step': 1.2715084552764893, 'train/conf_loss_step': 0.5390934348106384, 'train/cls_loss_step': 0.3828517496585846, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.574686527252197, 'epoch': 0, 'trainer/global_step': 394999, '_timestamp': 1751310039.0212927}).
wandb: WARNING (User provided step: 399999 is less than current step: 400000. Dropping entry: {'train/loss_step': 2.746095657348633, 'train/iou_loss_step': 1.431546926498413, 'train/conf_loss_step': 0.8932546377182007, 'train/cls_loss_step': 0.4212939441204071, 'train/l1_loss_step': 0.0, 'train/num_fg_step': 7.235772132873535, 'epoch': 0, 'trainer/global_step': 399999, '_timestamp': 1751315191.5171816}).
wandb: WARNING (User provided step: 399999 is less than current step: 400002. Dropping entry: {'val/AP': 0.39612764039330683, 'val/AP_50': 0.6709099548567934, 'val/AP_75': 0.4076149919351123, 'val/AP_S': 0.28670534472459563, 'val/AP_M': 0.439194145085395, 'val/AP_L': 0.486031662363613, 'epoch': 0, 'trainer/global_step': 399999, '_timestamp': 1751315760.9259555}).
wandb: WARNING (User provided step: 400000 is less than current step: 400002. Dropping entry: {'train/gradients': {'_type': 'plotly-file', 'sha256': 'da13c3d16ed1e78630d9cb796f8c3b6f3fc2701cdbc6b9bf70338802a56f39d7', 'size': 7784, 'path': 'media/plotly/train/gradients_400002_da13c3d16ed1e78630d9.plotly.json'}, 'trainer/global_step': 400000, '_timestamp': 1751315762.070991}).
wandb: WARNING (User provided step: 400000 is less than current step: 400002. Dropping entry: {'train/loss_epoch': 2.5159687995910645, 'train/iou_loss_epoch': 1.371797800064087, 'train/conf_loss_epoch': 0.7308478355407715, 'train/cls_loss_epoch': 0.41331905126571655, 'train/l1_loss_epoch': 0.0, 'train/num_fg_epoch': 7.413961887359619, 'epoch': 0, 'trainer/global_step': 400000, '_timestamp': 1751315762.6258407}).
