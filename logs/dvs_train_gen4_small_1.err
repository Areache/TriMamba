Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 71gtb3c6.
wandb: Tracking run with wandb version 0.16.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: logging graph, to disable use `wandb.watch(log_graph=False)`
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

creating rnd access train datasets: 0it [00:00, ?it/s]creating rnd access train datasets: 10it [00:00, 98.47it/s]creating rnd access train datasets: 20it [00:00, 98.13it/s]creating rnd access train datasets: 31it [00:00, 98.38it/s]creating rnd access train datasets: 49it [00:00, 127.94it/s]creating rnd access train datasets: 67it [00:00, 142.93it/s]creating rnd access train datasets: 83it [00:00, 146.67it/s]creating rnd access train datasets: 98it [00:00, 130.52it/s]creating rnd access train datasets: 114it [00:00, 138.72it/s]creating rnd access train datasets: 129it [00:00, 131.52it/s]creating rnd access train datasets: 143it [00:01, 130.00it/s]creating rnd access train datasets: 160it [00:01, 129.69it/s]creating rnd access train datasets: 180it [00:01, 147.02it/s]creating rnd access train datasets: 195it [00:01, 129.19it/s]creating rnd access train datasets: 216it [00:01, 142.75it/s]creating rnd access train datasets: 237it [00:01, 148.38it/s]creating rnd access train datasets: 253it [00:01creating rnd access train datasets: 0it [00:00, ?it/s]creating rnd access train datasets: 10it [00:00, 98.21it/s]creating rnd access train datasets: 20it [00:00, 97.87it/s]creating rnd access train datasets: 31it [00:00, 98.26it/s]creating rnd access train datasets: 49it [00:00, 127.96it/s]creating rnd access train datasets: 67it [00:00, 142.80it/s]creating rnd access train datasets: 83it [00:00, 146.48it/s]creating rnd access train datasets: 98it [00:00, 130.47it/s]creating rnd access train datasets: 115it [00:00, 139.81it/s]creating rnd access train datasets: 130it [00:01, 107.96it/s]creating rnd access train datasets: 159it [00:01, 151.01it/s]creating rnd access train datasets: 177it [00:01, 143.51it/s]creating rnd access train datasets: 193it [00:01, 128.84it/s]creating rnd access train datasets: 214it [00:01, 147.54it/s]creating rnd access train datasets: 231it [00:01, 153.12it/s]creating rnd access train datasets: 248it [00:01, 132.39it/s]creating rnd access train datasets: 266it [00:01creating rnd access train datasets: 0it [00:00, ?it/s]creating rnd access train datasets: 10it [00:00, 98.15it/s]creating rnd access train datasets: 20it [00:00, 97.99it/s]creating rnd access train datasets: 31it [00:00, 98.31it/s]creating rnd access train datasets: 49it [00:00, 127.89it/s]creating rnd access train datasets: 67it [00:00, 142.89it/s]creating rnd access train datasets: 83it [00:00, 146.63it/s]creating rnd access train datasets: 98it [00:00, 130.51it/s]creating rnd access train datasets: 114it [00:00, 138.80it/s]creating rnd access train datasets: 129it [00:01, 106.55it/s]creating rnd access train datasets: 159it [00:01, 151.56it/s]creating rnd access train datasets: 177it [00:01, 143.91it/s]creating rnd access train datasets: 193it [00:01, 129.07it/s]creating rnd access train datasets: 214it [00:01, 147.77it/s]creating rnd access train datasets: 231it [00:01, 153.28it/s]creating rnd access train datasets: 248it [00:01, 132.58it/s]creating rnd access train datasets: 266it [00:01creating rnd access train datasets: 0it [00:00, ?it/s]creating rnd access train datasets: 10it [00:00, 98.05it/s]creating rnd access train datasets: 20it [00:00, 98.09it/s]creating rnd access train datasets: 31it [00:00, 98.36it/s]creating rnd access train datasets: 49it [00:00, 127.82it/s]creating rnd access train datasets: 67it [00:00, 142.96it/s]creating rnd access train datasets: 83it [00:00, 146.68it/s]creating rnd access train datasets: 98it [00:00, 130.53it/s]creating rnd access train datasets: 114it [00:00, 138.82it/s]creating rnd access train datasets: 129it [00:01, 105.59it/s]creating rnd access train datasets: 160it [00:01, 137.23it/s]creating rnd access train datasets: 180it [00:01, 150.52it/s]creating rnd access train datasets: 197it [00:01, 134.34it/s]creating rnd access train datasets: 216it [00:01, 144.34it/s]creating rnd access train datasets: 237it [00:01, 149.17it/s]creating rnd access train datasets: 253it [00:01, 138.63it/s]creating rnd access train datasets: 269it [00:01, 137.68it/s]creating rnd access train datasets: 269it [00:01, 142.55it/s]creating rnd access train datasets: 290it [00:02, 158.77it/s]creating rnd access train datasets: 307it [00:02, 159.00it/s]creating rnd access train datasets: 327it [00:02, 163.25it/s]creating rnd access train datasets: 348it [00:02, 175.60it/s]creating rnd access train datasets: 369it [00:02, 184.15it/s]creating rnd access train datasets: 388it [00:02, 162.03it/s]creating rnd access train datasets: 405it [00:02, 154.32it/s]creating rnd access train datasets: 421it [00:02, 141.01it/s]creating rnd access train datasets: 442it [00:03, 158.36it/s]creating rnd access train datasets: 464it [00:03, 173.31it/s]creating rnd access train datasets: 482it [00:03, 165.05it/s]creating rnd access train datasets: 499it [00:03, 148.57it/s]creating rnd access train datasets: 515it [00:03, 142.86it/s]creating rnd access train datasets: 537it [00:03, 162.21it/s]creating rnd access train datasets: 558it [00:03, 172.76it/s]creating rnd acces, 140.77it/s]creating rnd access train datasets: 286it [00:02, 154.64it/s]creating rnd access train datasets: 304it [00:02, 157.90it/s]creating rnd access train datasets: 325it [00:02, 170.28it/s]creating rnd access train datasets: 343it [00:02, 170.08it/s]creating rnd access train datasets: 365it [00:02, 182.08it/s]creating rnd access train datasets: 384it [00:02, 159.55it/s]creating rnd access train datasets: 401it [00:02, 153.41it/s]creating rnd access train datasets: 417it [00:02, 145.81it/s]creating rnd access train datasets: 435it [00:02, 153.47it/s]creating rnd access train datasets: 457it [00:03, 169.54it/s]creating rnd access train datasets: 475it [00:03, 162.58it/s]creating rnd access train datasets: 492it [00:03, 147.37it/s]creating rnd access train datasets: 511it [00:03, 154.03it/s]creating rnd access train datasets: 527it [00:03, 154.78it/s]creating rnd access train datasets: 549it [00:03, 170.83it/s]creating rnd access train datasets: 567it [00:03, 141.83it/s]creating rnd acces, 140.79it/s]creating rnd access train datasets: 286it [00:02, 154.68it/s]creating rnd access train datasets: 304it [00:02, 157.72it/s]creating rnd access train datasets: 325it [00:02, 170.15it/s]creating rnd access train datasets: 343it [00:02, 170.10it/s]creating rnd access train datasets: 365it [00:02, 181.91it/s]creating rnd access train datasets: 384it [00:02, 159.51it/s]creating rnd access train datasets: 401it [00:02, 153.48it/s]creating rnd access train datasets: 417it [00:02, 145.74it/s]creating rnd access train datasets: 435it [00:02, 153.55it/s]creating rnd access train datasets: 457it [00:03, 169.59it/s]creating rnd access train datasets: 475it [00:03, 162.62it/s]creating rnd access train datasets: 492it [00:03, 147.18it/s]creating rnd access train datasets: 511it [00:03, 154.12it/s]creating rnd access train datasets: 527it [00:03, 154.84it/s]creating rnd access train datasets: 549it [00:03, 170.70it/s]creating rnd access train datasets: 567it [00:03, 141.89it/s]creating rnd acces, 143.14it/s]creating rnd access train datasets: 290it [00:02, 158.86it/s]creating rnd access train datasets: 307it [00:02, 159.17it/s]creating rnd access train datasets: 327it [00:02, 163.44it/s]creating rnd access train datasets: 348it [00:02, 175.55it/s]creating rnd access train datasets: 369it [00:02, 183.93it/s]creating rnd access train datasets: 388it [00:02, 161.97it/s]creating rnd access train datasets: 405it [00:02, 154.40it/s]creating rnd access train datasets: 421it [00:02, 141.16it/s]creating rnd access train datasets: 442it [00:03, 158.48it/s]creating rnd access train datasets: 464it [00:03, 173.17it/s]creating rnd access train datasets: 482it [00:03, 165.13it/s]creating rnd access train datasets: 499it [00:03, 148.65it/s]creating rnd access train datasets: 515it [00:03, 142.83it/s]creating rnd access train datasets: 537it [00:03, 162.18it/s]creating rnd access train datasets: 558it [00:03, 172.74it/s]creating rnd access train datasets: 576it [00:03, 137.67it/s]creating rnd access train datasets: 583it [00:03, 140.60it/s]creating rnd access train datasets: 603it [00:04, 153.93it/s]creating rnd access train datasets: 620it [00:04, 149.28it/s]creating rnd access train datasets: 638it [00:04, 140.63it/s]creating rnd access train datasets: 657it [00:04, 152.61it/s]creating rnd access train datasets: 678it [00:04, 166.64it/s]creating rnd access train datasets: 681it [00:04, 148.97it/s]
s train datasets: 583it [00:03, 140.56it/s]creating rnd access train datasets: 603it [00:04, 153.90it/s]creating rnd access train datasets: 620it [00:04, 149.35it/s]creating rnd access train datasets: 638it [00:04, 140.59it/s]creating rnd access train datasets: 657it [00:04, 152.57it/s]creating rnd access train datasets: 678it [00:04, 166.72it/s]creating rnd access train datasets: 681it [00:04, 148.97it/s]
s train datasets: 592it [00:04, 142.93it/s]creating rnd access train datasets: 608it [00:04, 140.48it/s]creating rnd access train datasets: 629it [00:04, 157.05it/s]creating rnd access train datasets: 646it [00:04, 143.36it/s]creating rnd access train datasets: 666it [00:04, 157.36it/s]creating rnd access train datasets: 681it [00:04, 148.97it/s]
s train datasets: 576it [00:03, 137.69it/s]creating rnd access train datasets: 592it [00:04, 142.93it/s]creating rnd access train datasets: 608it [00:04, 136.33it/s]creating rnd access train datasets: 632it [00:04, 160.41it/s]creating rnd access train datasets: 649it [00:04, 144.61it/s]creating rnd access train datasets: 670it [00:04, 160.30it/s]creating rnd access train datasets: 681it [00:04, 148.97it/s]
creating streaming train datasets: 0it [00:00, ?it/s]creating streaming train datasets: 10it [00:00, 97.30it/s]creating streaming train datasets: 26it [00:00, 133.02it/s]creating streaming train datasets: 40it [00:00, 106.36it/s]creating streaming train datasets: 58it [00:00, 130.06it/s]creating streaming train datasets: 74it [00:00, 139.34it/s]creating streaming train datasets: 91it [00:00, 147.74it/s]creating streaming train datasets: 107it [00:00, 149.38it/s]creating streaming train datasets: 123it [00:00, 139.31it/s]creating streaming train datasets: 139it [00:01, 139.36it/s]creating streaming train datasets: 154it [00:01, 131.46it/s]creating streaming train datasets: 175it [00:01, 151.50it/s]creating streaming train datasets: 195it [00:01, 162.16it/s]creating streaming train datasets: 212it [00:01, 161.43it/s]creating streaming train datasets: 234it [00:01, 176.57it/s]creating streaming train datasets: 252it [00:01, 155.96it/s]creating streaming train datasets: 271it [00:01, 164.39it/s]creating streaming train datasets: 0it [00:00, ?it/s]creating streaming train datasets: 10it [00:00, 96.59it/s]creating streaming train datasets: 26it [00:00, 132.57it/s]creating streaming train datasets: 40it [00:00, 106.27it/s]creating streaming train datasets: 58it [00:00, 130.03it/s]creating streaming train datasets: 74it [00:00, 139.23it/s]creating streaming train datasets: 91it [00:00, 147.66it/s]creating streaming train datasets: 107it [00:00, 149.37it/s]creating streaming train datasets: 123it [00:00, 139.30it/s]creating streaming train datasets: 139it [00:01, 139.45it/s]creating streaming train datasets: 154it [00:01, 131.38it/s]creating streaming train datasets: 176it [00:01, 153.92it/s]creating streaming train datasets: 198it [00:01, 162.64it/s]creating streaming train datasets: 218it [00:01, 169.42it/s]creating streaming train datasets: 238it [00:01, 158.48it/s]creating streaming train datasets: 255it [00:01, 159.60it/s]creating streaming train datasets: 275it [00:01, 168.30it/s]creating streaming train datasets: 0it [00:00, ?it/s]creating streaming train datasets: 10it [00:00, 96.82it/s]creating streaming train datasets: 26it [00:00, 132.72it/s]creating streaming train datasets: 40it [00:00, 106.27it/s]creating streaming train datasets: 58it [00:00, 130.04it/s]creating streaming train datasets: 74it [00:00, 139.28it/s]creating streaming train datasets: 91it [00:00, 147.69it/s]creating streaming train datasets: 107it [00:00, 149.34it/s]creating streaming train datasets: 123it [00:00, 139.29it/s]creating streaming train datasets: 139it [00:01, 139.51it/s]creating streaming train datasets: 154it [00:01, 131.42it/s]creating streaming train datasets: 176it [00:01, 153.83it/s]creating streaming train datasets: 198it [00:01, 162.73it/s]creating streaming train datasets: 217it [00:01, 170.13it/s]creating streaming train datasets: 238it [00:01, 157.53it/s]creating streaming train datasets: 255it [00:01, 159.67it/s]creating streaming train datasets: 275it [00:01, 168.30it/s]creating streaming train datasets: 0it [00:00, ?it/s]creating streaming train datasets: 10it [00:00, 97.01it/s]creating streaming train datasets: 26it [00:00, 132.85it/s]creating streaming train datasets: 40it [00:00, 106.24it/s]creating streaming train datasets: 58it [00:00, 130.08it/s]creating streaming train datasets: 74it [00:00, 139.31it/s]creating streaming train datasets: 91it [00:00, 147.72it/s]creating streaming train datasets: 107it [00:00, 149.28it/s]creating streaming train datasets: 123it [00:00, 139.28it/s]creating streaming train datasets: 139it [00:01, 139.53it/s]creating streaming train datasets: 154it [00:01, 131.45it/s]creating streaming train datasets: 176it [00:01, 153.90it/s]creating streaming train datasets: 198it [00:01, 162.58it/s]creating streaming train datasets: 218it [00:01, 169.25it/s]creating streaming train datasets: 238it [00:01, 158.01it/s]creating streaming train datasets: 255it [00:01, 159.79it/s]creating streaming train datasets: 275it [00:01, 168.44it/s]creating streaming train datasets: 293it [00:01, 165.19it/s]creating streaming train datasets: 310it [00:02, 157.24it/s]creating streaming train datasets: 326it [00:02, 147.42it/s]creating streaming train datasets: 344it [00:02, 143.12it/s]creating streaming train datasets: 359it [00:02, 141.30it/s]creating streaming train datasets: 378it [00:02, 153.99it/s]creating streaming train datasets: 394it [00:02, 145.11it/s]creating streaming train datasets: 412it [00:02, 153.97it/s]creating streaming train datasets: 428it [00:02, 150.40it/s]creating streaming train datasets: 444it [00:02, 148.22it/s]creating streaming train datasets: 461it [00:03, 138.80it/s]creating streaming train datasets: 479it [00:03, 148.60it/s]creating streaming train datasets: 495it [00:03, 133.38it/s]creating streaming train datasets: 512it [00:03, 141.42it/s]creating streaming train datasets: 527it [00:03, 133.49it/s]creating streaming train datasets: 541it [00:03, 124.03it/s]creating streaming train datasets: 557it [00:03,creating streaming train datasets: 293it [00:01, 165.23it/s]creating streaming train datasets: 310it [00:02, 157.36it/s]creating streaming train datasets: 326it [00:02, 147.43it/s]creating streaming train datasets: 344it [00:02, 142.60it/s]creating streaming train datasets: 359it [00:02, 141.57it/s]creating streaming train datasets: 378it [00:02, 154.13it/s]creating streaming train datasets: 394it [00:02, 145.16it/s]creating streaming train datasets: 412it [00:02, 153.76it/s]creating streaming train datasets: 428it [00:02, 150.59it/s]creating streaming train datasets: 444it [00:02, 148.34it/s]creating streaming train datasets: 461it [00:03, 138.84it/s]creating streaming train datasets: 479it [00:03, 148.49it/s]creating streaming train datasets: 495it [00:03, 130.94it/s]creating streaming train datasets: 513it [00:03, 142.09it/s]creating streaming train datasets: 528it [00:03, 135.26it/s]creating streaming train datasets: 542it [00:03, 125.26it/s]creating streaming train datasets: 558it [00:03,creating streaming train datasets: 293it [00:02, 138.63it/s]creating streaming train datasets: 308it [00:02, 126.18it/s]creating streaming train datasets: 326it [00:02, 138.54it/s]creating streaming train datasets: 342it [00:02, 142.82it/s]creating streaming train datasets: 357it [00:02, 135.22it/s]creating streaming train datasets: 374it [00:02, 137.85it/s]creating streaming train datasets: 389it [00:02, 135.36it/s]creating streaming train datasets: 405it [00:02, 139.63it/s]creating streaming train datasets: 420it [00:02, 124.50it/s]creating streaming train datasets: 437it [00:03, 135.50it/s]creating streaming train datasets: 452it [00:03, 136.91it/s]creating streaming train datasets: 470it [00:03, 142.21it/s]creating streaming train datasets: 485it [00:03, 121.98it/s]creating streaming train datasets: 498it [00:03, 118.43it/s]creating streaming train datasets: 518it [00:03, 128.40it/s]creating streaming train datasets: 532it [00:03, 127.65it/s]creating streaming train datasets: 549it [00:03,creating streaming train datasets: 288it [00:01, 164.59it/s]creating streaming train datasets: 305it [00:02, 152.72it/s]creating streaming train datasets: 321it [00:02, 146.66it/s]creating streaming train datasets: 343it [00:02, 157.74it/s]creating streaming train datasets: 359it [00:02, 140.14it/s]creating streaming train datasets: 378it [00:02, 152.52it/s]creating streaming train datasets: 394it [00:02, 143.86it/s]creating streaming train datasets: 412it [00:02, 152.58it/s]creating streaming train datasets: 428it [00:02, 150.42it/s]creating streaming train datasets: 444it [00:03, 146.18it/s]creating streaming train datasets: 461it [00:03, 132.99it/s]creating streaming train datasets: 478it [00:03, 141.86it/s]creating streaming train datasets: 493it [00:03, 113.28it/s]creating streaming train datasets: 506it [00:03, 114.10it/s]creating streaming train datasets: 526it [00:03, 133.79it/s]creating streaming train datasets: 541it [00:03, 111.02it/s]creating streaming train datasets: 562it [00:03, 133.59it/s]creating streaming train datasets: 574it [00:03, 140.26it/s]creating streaming train datasets: 589it [00:04, 129.43it/s]creating streaming train datasets: 610it [00:04, 148.55it/s]creating streaming train datasets: 626it [00:04, 141.73it/s]creating streaming train datasets: 645it [00:04, 153.99it/s]creating streaming train datasets: 661it [00:04, 144.79it/s]creating streaming train datasets: 676it [00:04, 138.39it/s]creating streaming train datasets: 681it [00:04, 143.95it/s]
 133.08it/s]creating streaming train datasets: 572it [00:03, 136.36it/s]creating streaming train datasets: 586it [00:04, 135.06it/s]creating streaming train datasets: 601it [00:04, 138.74it/s]creating streaming train datasets: 621it [00:04, 154.89it/s]creating streaming train datasets: 637it [00:04, 150.44it/s]creating streaming train datasets: 653it [00:04, 136.03it/s]creating streaming train datasets: 672it [00:04, 149.32it/s]creating streaming train datasets: 681it [00:04, 143.39it/s]
 126.09it/s]creating streaming train datasets: 576it [00:04, 122.08it/s]creating streaming train datasets: 594it [00:04, 133.97it/s]creating streaming train datasets: 609it [00:04, 136.53it/s]creating streaming train datasets: 626it [00:04, 144.36it/s]creating streaming train datasets: 641it [00:04, 135.62it/s]creating streaming train datasets: 663it [00:04, 153.56it/s]creating streaming train datasets: 679it [00:04, 153.68it/s]creating streaming train datasets: 681it [00:04, 141.48it/s]
 138.31it/s]creating streaming train datasets: 565it [00:04, 142.58it/s]creating streaming train datasets: 580it [00:04, 139.44it/s]creating streaming train datasets: 596it [00:04, 142.12it/s]creating streaming train datasets: 612it [00:04, 146.95it/s]creating streaming train datasets: 627it [00:04, 130.38it/s]creating streaming train datasets: 645it [00:04, 142.38it/s]creating streaming train datasets: 660it [00:04, 139.99it/s]creating streaming train datasets: 676it [00:04, 140.63it/s]creating streaming train datasets: 681it [00:04, 138.94it/s]
creating streaming val datasets: 0it [00:00, ?it/s]creating streaming val datasets: 22it [00:00, 218.56it/s]creating streaming val datasets: 44it [00:00, 194.65it/s]creating streaming val datasets: 67it [00:00, 205.62it/s]creating streaming val datasets: 88it [00:00, 136.54it/s]creating streaming val datasets: 105it [00:00, 127.52it/s]creating streaming val datasets: 120it [00:00, 107.00it/s]creating streaming val datasets: 128it [00:01, 127.40it/s]
creating streaming val datasets: 0it [00:00, ?it/s]creating streaming val datasets: 17it [00:00, 140.31it/s]creating streaming val datasets: 32it [00:00, 120.47it/s]creating streaming val datasets: 48it [00:00, 118.80it/s]creating streaming val datasets: 67it [00:00, 141.59it/s]creating streaming val datasets: 82it [00:00, 107.27it/s]creating streaming val datasets: 102it [00:00, 129.01it/s]creating streaming val datasets: 117it [00:01, 103.22it/s]creating streaming val datasets: 128it [00:01, 108.91it/s]
creating streaming val datasets: 0it [00:00, ?it/s]creating streaming val datasets: 17it [00:00, 166.70it/s]creating streaming val datasets: 34it [00:00, 128.82it/s]creating streaming val datasets: 48it [00:00, 122.12it/s]creating streaming val datasets: 67it [00:00, 144.48it/s]creating streaming val datasets: 82it [00:00, 108.16it/s]creating streaming val datasets: 102it [00:00, 129.86it/s]creating streaming val datasets: 117it [00:01, 103.55it/s]creating streaming val datasets: 128it [00:01, 110.61it/s]
creating streaming val datasets: 0it [00:00, ?it/s]creating streaming val datasets: 23it [00:00, 226.85it/s]creating streaming val datasets: 46it [00:00, 174.60it/s]creating streaming val datasets: 65it [00:00, 151.51it/s]creating streaming val datasets: 81it [00:00, 113.30it/s]creating streaming val datasets: 101it [00:00, 133.26it/s]creating streaming val datasets: 116it [00:00, 105.90it/s]creating streaming val datasets: 128it [00:01, 117.20it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name           | Type          | Params | Mode 
---------------------------------------------------------
0 | mdl            | YoloXDetector | 13.3 M | train
1 | mdl.backbone   | RNNDetector   | 10.7 M | train
2 | mdl.fpn        | YOLOPAFPN     | 1.6 M  | train
3 | mdl.yolox_head | YOLOXHead     | 1.1 M  | train
---------------------------------------------------------
13.3 M    Trainable params
0         Non-trainable params
13.3 M    Total params
53.291    Total estimated model params size (MB)
441       Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/autograd/__init__.py:266: UserWarning:

Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1, 96, 1, 1], strides() = [96, 1, 96, 96]
bucket_view.sizes() = [1, 96, 1, 1], strides() = [96, 1, 1, 1] (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/torch/csrc/distributed/c10d/reducer.cpp:322.)

/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1, 96, 1, 1], strides() = [96, 1, 96, 96]
bucket_view.sizes() = [1, 96, 1, 1], strides() = [96, 1, 1, 1] (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1, 96, 1, 1], strides() = [96, 1, 96, 96]
bucket_view.sizes() = [1, 96, 1, 1], strides() = [96, 1, 1, 1] (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/leonardo/home/userexternal/ychen004/anaconda3/envs/events_signals/lib/python3.11/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1, 96, 1, 1], strides() = [96, 1, 96, 96]
bucket_view.sizes() = [1, 96, 1, 1], strides() = [96, 1, 1, 1] (Triggered internally at /opt/conda/conda-bld/pytorch_1708025842427/work/torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
